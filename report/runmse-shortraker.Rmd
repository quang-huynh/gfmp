\clearpage

# SHORTRAKER ROCKFISH: MANAGEMENT PROCEDURE SPECIFICATIONS {#app:desc-mp-sr}

For now pick out some measure procedures that look plausible for our data. The next step is to run our data through the data conversion function and run `DLMtool::can()`. FIXME

```{r}
mp <- c(
  # "DCAC",
  # "DCAC_40",
  "DBSRA4010",
  # "DBSRA",
  # "DBSRA_40",
  "DCAC4010",
  "AvC",
  "CC1",
  # "CC2",
  # "CC3",
  # "CC4",
  # "CC5",
  "SPSRA",
  "SPMSY",
  "NFref",
  "FMSYref",
  "FMSYref50",
  # "DD",
  "DD4010",
  "GB_CC")
mp <- sort(mp)

```

```{r, results='asis'}
csasdown::csas_table(MPtype(mp))
```

# SHORTRAKER ROCKFISH: RESULTS

## Constructing the operating model

First, let's combine the stock, fleet, observation, and mp objects into a complete operating model:

```{r}
# avail("Output")
# avail("Reference")
```

```{r echo = TRUE}
om <- new('OM', stock, fleet, obs, imp)

om@nsim <- 200

saveRDS(om, file = here::here("generated-data", "shortraker-om.rds"))
```

There are a variety of built-in plotting functions to examine the components of the operating model:

We may want to develop our own plotting functions.

What are the essential plots to show?

* M as a distribution (and a timeseries if we were letting it change through time)
* vonB curves (this takes care of linf, K, t0 parameters)

Debatably these are already indicated by the filling of the slots before.

Selection and retention curves are a bit more important perhaps to visualize other slots translate into a shape.

Only need to show for one year unless there are time varying effects.


```{r, eval=TRUE, fig.asp=1, eval=FALSE}
pdf(here::here("report/ignore.pdf"))
x <- plotStock(om, nsamp = 5)
dev.off()

nsamp <- 3
nsim <- length(x$M)
its <- sample(seq_len(nsim), nsamp)
x$Marray
x$M_ageArray
x$Len_age
x$Wt_age
```

```{r, eval=TRUE}
plotSelect(om, sim = 1) # one sample, others will look different
```

```{r, eval=TRUE, fig.asp=1}
plotFleet(fleet, Stock = stock)
```

```{r, eval=TRUE, fig.asp=1}
plotImp(imp)
```

```{r, eval=TRUE, fig.asp=0.8}
plotObs(obs)
```

One thing we can do to check our operating model calibration is check some random samples from the historical simulation against our observed data. For example, here are 11 samples from the simulated historical catch timeseries compared to the observed (reconstructed/corrected) catch timeseries.

```{r, fig.asp=0.8}
original_nsim <- om@nsim
om@nsim <- 50L
short_historical <- runMSE(om, Hist = TRUE, parallel=TRUE, ntrials=1000)
om@nsim <- original_nsim

# names(short_historical@TSdata)
# dim(short_historical@TSdata$Catch)

real_catch <- read.csv(here::here("report/data/shortraker-corrected-catch.csv"))
real_catch <- mutate(real_catch, synthetic = ifelse(Year >= 1990 & Year <= 1995, Predicted.catch, Observed.catch))

all_years <- data.frame(Year = (2018 - fleet@nyears):2018)
real_catch <- dplyr::left_join(all_years, real_catch)

set.seed(1567)
catch <- short_historical@TSdata$Catch %>%
  reshape2::melt() %>%
  dplyr::filter(Var1 %in% sample(unique(Var1), size = 11)) %>%
  transmute(sample_id = Var1, year = Var2 + min(real_catch$Year) - 1,
    catch = value, type = "Simulated") %>%
  bind_rows(data.frame(sample_id = 0, year = real_catch$Year,
    catch = real_catch$synthetic, type = "Observed", stringsAsFactors = FALSE))

catch %>%
  filter(!is.na(catch)) %>%
  group_by(sample_id) %>%
  mutate(catch = catch/max(catch)) %>%
  ggplot(aes(year, catch, colour = type)) +
  geom_line() +
  facet_wrap(~sample_id) +
  ylab("Historical catch") +
  xlab("Year")

short_historical@TSdata$B %>%
  reshape2::melt() %>%
  dplyr::filter(Var1 %in% sample(unique(Var1), size = 12)) %>%
  ggplot(aes(Var2, value)) +
  geom_line() +
  facet_wrap(~Var1, scales = "free_y") +
  ylab("Simulated historical biomass") +
  xlab("Year")

# short_data <- pbs2dlm::create_dlm_data(d)
# DLMtool::Turing(OM = om, Data = short_data, wait = FALSE)
```

Now we can run closed-loop simulation:

```{r, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
.parallel <- !identical(.Platform$OS.type, "windows")
file_name <- here::here("generated-data", "shortraker-mse.rds")
om@seed <- 2849281
if (!file.exists(file_name)) {
  if (.parallel) DLMtool::setup(cpus = parallel::detectCores())
  short_mse <- runMSE(OM = om, MPs = mp, parallel=TRUE, ntrials=1000)
  saveRDS(short_mse, file = file_name)
} else {
  short_mse <- readRDS(file_name)
}
```

Check convergence:

```{r}
DLMtool::Converge(short_mse)
```

```{r probability-table-abs, fig.width = 9, fig.asp = 1, out.width = "4in"}
probs <- get_probs(short_mse, PMlist = c("P40", "P80", "PNOF", "AAVY", "LTY"))
plot_probs(probs)
```

```{r probability-table-0-1, fig.width = 9, fig.asp = 1, out.width = "4in"}
plot_probs(probs, scale_0_1 = TRUE)
```

Illustrating the built-in plotting functions:

```{r}
x <- trade_off(short_mse,
               pm_list = list("PNOF", "LTY", "P100", "LTY", "P50", "LTY", "P10", "LTY"),
               lims = c(0.5, 0.5, 0.5, 0.5))
Tplot(short_mse)
Tplot2(short_mse)
```


```{r}
wormplot(short_mse)
```

```{r}
Pplot(short_mse)
Pplot2(short_mse)
```

```{r}
Pplot2(short_mse, traj="quant", quants=c(0.2, 0.8))
```

```{r}
Kplot(short_mse)
```

```{r}
Cplot(short_mse)
```

And examine the output.

```{r}
#plot(short_mse)
oldpar <- par()
##DFO_hist(short_mse)
#par(mfrow = c(1, 1))
DFO_plot(short_mse)
# DFO_plot2(short_mse)
```

```{r, fig.asp=1, warning=FALSE}
DFO_proj(short_mse)
#DFO_hist(short_om)
# DFO_plot2(short_mse)

# d <- DFO_plot2(short_mse)
# ggplot(d, aes(B50/100, LTY/100, label = MPs, colour = Satisfice)) +
#   geom_vline(xintercept = 0.5, col = "grey50") +
#   geom_hline(yintercept = 0.5, col = "grey50") +
#   geom_text() + ggsidekick::theme_sleek() +
#   scale_colour_manual(values = c("grey60", "black")) +
#   guides(colour = FALSE) +
#   xlab(expression(Pr(B>0.5~B[MSY]))) +
#   ylab(expression(Pr(yield>0.5~yield~at~F[MSY]))) +
#   xlim(0, 1) + ylim(0, 1)
par(oldpar)
```

The following are some plots I was playing with a long time ago. We should wrap the useful ones into their own functions in our package.

```{r, mp-contour, fig.asp=1}
plot_contours(short_mse, dontshow_mp = "NFref")
```

```{r, fig.asp=1.9, out.width = "4.8in", fig.width=7}
library(dplyr)
library(RColorBrewer)
ffmsy <- short_mse@F_FMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, ffmsy = value, year = Var3)
bbmsy <- short_mse@B_BMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, bbmsy = value, year = Var3)
d <- dplyr::inner_join(ffmsy, bbmsy)
d <- dplyr::left_join(d, n)
d <- reshape2::melt(d, id.vars = c("iter", "mp", "year", "mp_name"))
levels(d$variable) <- c(expression(F/F[MSY]), expression(B/B[MSY]))

d_median <- d %>% group_by(mp_name, year, variable) %>%
  summarise(median_value = median(value)) %>%
  mutate(iter = NA)

fudge <- 3.5
d$over <- FALSE
d$over[d$value > fudge] <- TRUE
d$value[d$over] <- fudge
d_median$median_value[d_median$median_value > fudge] <- fudge

d_last <- dplyr::filter(d, year == max(year)) %>%
  select(-over, -year) %>%
  rename(last_value = value)
d <- inner_join(d, d_last)

cols <- brewer.pal(3, "RdBu")
cols[2] <- "grey80"

plot_timeseries <- function(dat, dat_median, title = "",
  ylim = c(0, fudge), cols, values, labels = TRUE, yaxis = TRUE) {
  g <- ggplot(dat, aes_string("year", "value", group = "iter")) +
    geom_line(aes_string(colour = "last_value"), alpha = 0.3) +
    facet_grid(mp_name~., labeller = label_parsed) +
    ggsidekick::theme_sleek() +
    scale_colour_gradientn(colours = cols,
      values = values) +
    geom_line(data = dat_median, aes_string("year", "median_value"),
      colour = "black", lwd = 1.5) +
    ylim(ylim[1], ylim[2]) +
    ggtitle(title) +
    guides(colour = FALSE) +
    ylab("Value") + xlab("Year")

  if (!labels)
    g <- g + theme(strip.background = element_blank(),
      strip.text.y = element_blank())

  if (!yaxis)
    g <- g + theme(axis.text.y = element_blank())
  g
}

cols <- brewer.pal(5, "RdBu")
cols <- c(cols[1], "grey50", cols[length(cols)])
set.seed(42)
# d_ <- filter(d, iter %in% sample(seq_len(max(d$iter)), 30))
d_ <- d

# plot_timeseries(d, d_median,
# cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)))

# mps <- c("DCAC", "DCAC_40")
# p1 <- plot_timeseries(filter(d_, variable == "B/B[MSY]", mp_name %in% mps),
#   filter(d_median, variable == "B/B[MSY]", mp_name %in% mps), expression(B/B[MSY]),
#   cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)),
#   labels = TRUE)
# p2 <- plot_timeseries(filter(d_, variable == "F/F[MSY]", mp_name %in% mps),
#   filter(d_median, variable == "F/F[MSY]", mp_name %in% mps), expression(F/F[MSY]),
#   cols = cols, values = scales::rescale(c(fudge, 1.2, 0.8, 0)),
#   labels = TRUE, yaxis = TRUE)
# gridExtra::grid.arrange(p1, p2, ncol = 2)

# pdf("analysis/short-bbmsy-ffmsy-ts-ex.pdf", width = 6, height = 3.5)
# gridExtra::grid.arrange(p1, p2, ncol = 2)
# dev.off()

# mps <- unique(d_$mp_name)
# # mps <- mps[-which(mps %in% c("CC4"))]
# p1 <- plot_timeseries(filter(d_, variable == "B/B[MSY]", mp_name %in% mps),
#   filter(d_median, variable == "B/B[MSY]", mp_name %in% mps), expression(B/B[MSY]),
#   cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)),
#   labels = TRUE)
# p2 <- plot_timeseries(filter(d_, variable == "F/F[MSY]", mp_name %in% mps),
#   filter(d_median, variable == "F/F[MSY]", mp_name %in% mps), expression(F/F[MSY]),
#   cols = cols, values = scales::rescale(c(fudge, 1.2, 0.8, 0)),
#   labels = TRUE, yaxis = TRUE)
# gridExtra::grid.arrange(p1, p2, ncol = 2)

# pdf("analysis/short-bbmsy-ffmsy-ts-ex-all.pdf", width = 6, height = 6)
# gridExtra::grid.arrange(p1, p2, ncol = 2)
# dev.off()

mps <- unique(d_$mp_name)
iters <- sample(unique(d_$iter), 50L)
# mps <- mps[-which(mps %in% c("CC4"))]
p1 <- plot_timeseries(filter(d_, variable == "B/B[MSY]", mp_name %in% mps, iter %in% iters),
  filter(d_median, variable == "B/B[MSY]", mp_name %in% mps), expression(B/B[MSY]),
  cols = cols, values = scales::rescale(c(0, 0.8, 1.2, fudge)),
  labels = TRUE)
p2 <- plot_timeseries(filter(d_, variable == "F/F[MSY]", mp_name %in% mps, iter %in% iters),
  filter(d_median, variable == "F/F[MSY]", mp_name %in% mps), expression(F/F[MSY]),
  cols = cols, values = scales::rescale(c(fudge, 1.2, 0.8, 0)),
  labels = TRUE, yaxis = TRUE)
gridExtra::grid.arrange(p2, p1, ncol = 2)

# pdf("analysis/short-bbmsy-ffmsy-ts-ex-all.pdf", width = 6, height = 6)
# gridExtra::grid.arrange(p1, p2, ncol = 2)
# dev.off()

#########3
ffmsy <- short_mse@F_FMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, ffmsy = value, year = Var3)
bbmsy <- short_mse@B_BMSY[,,] %>% reshape2::melt() %>%
  dplyr::rename(iter = Var1, mp = Var2, bbmsy = value, year = Var3)
d <- dplyr::inner_join(ffmsy, bbmsy)
d <- dplyr::left_join(d, n)
d <- reshape2::melt(d, id.vars = c("iter", "mp", "year", "mp_name"))
levels(d$variable) <- c(expression(F/F[MSY]), expression(B/B[MSY]))

d_sum <- d %>% group_by(mp_name, year, variable) %>%
  summarise(median_value = median(value),
    l = quantile(value, probs = 0.75),
    u = quantile(value, probs = 0.25),
    ll = quantile(value, probs = 0.95),
    uu = quantile(value, probs = 0.05))


# d_sum$median_value[d_sum$median_value > fudge] <- fudge
# d_sum$u[d_sum$u > fudge] <- fudge
# d_sum$l[d_sum$l > fudge] <- fudge

d <- inner_join(d, d_last)

d$last_value[d$last_value > fudge] <- fudge
# d$value[d$value > fudge] <- fudge


cols <- brewer.pal(5, "RdBu")
cols <- c(cols[1], "grey50", cols[length(cols)])
g <- ggplot(d_sum, aes_string("year", "median_value")) +
  facet_grid(mp_name~variable, labeller = label_parsed) +
  geom_ribbon(aes(ymin = ll, ymax = uu), fill = "grey90") +
  geom_ribbon(aes(ymin = l, ymax = u), fill = "grey70") +
  ggsidekick::theme_sleek() +
  geom_line(lwd = 1.5) +
  coord_cartesian(ylim = c(0, 4)) +
  guides(colour = FALSE) +
  xlim(25, 50) +
  geom_hline(yintercept = 1,
    col = "black", lty = 2) +
  ylab("Value") + xlab("Year")
  # geom_line(data = filter(d, iter %in% c(1:10)),
  #   aes(y = value, group = iter),
  #   alpha = 0.4, colour = "blue")
  # scale_colour_gradientn(colours = cols,
  #     values = c(0, 0.8, 1.2, 3))
  # viridis::scale_colour_viridis()
g
```

```{r, fig.asp=1.2}
voi_out <- DLMtool::VOI(short_mse)
```

```{r}
# AvC <- .dshort$catch %>% gfplot::tidy_catch() %>% group_by(year) %>%
#   summarize(catch = sum(value)) %>% pull(catch) %>% mean()
# AvC <- AvC / 1000

.c <- readr::read_csv(here::here("report/data/shortraker-corrected-catch.csv"))
AvC <- .c$`Predicted catch` * 1e3
plot(AvC)
AvC <- mean(AvC)

short_dat <- new('Data')                            #  Create a blank DLM object
short_dat@Name <- 'Shortraker Rockfish'             #  Name it
short_dat@Units <- "T"                              #  units of catch
short_dat@AvC <- AvC                                #  Average catches for time t (DCAC)
short_dat@t <- 41
short_dat@Year <- 1977:2018
short_dat@t <- 2018 - 1977
short_dat@LHYear <- 2018

short_dat@Mort <- 0.03                              #  Natural mortality rate
short_dat@CV_Mort <- 0.2

short_dat@BMSY_B0 <- 0.40                           #  BMSY relative to unfished
short_dat@CV_BMSY_B0 <- 0.045

short_dat@Dt <- 0.6                                 #  Depletion over time t (DCAC)
short_dat@CV_Dt <- 0.4

short_dat@FMSY_M <- 0.75                            #  Ratio of FMSY/M
short_dat@CV_FMSY_M <- 0.2

# Fease(short_dat)
xx <- runMP(short_dat, MPs = "DCAC4010", reps = 10000)
tac <- as.vector(xx@TAC)
hist(tac, breaks = 40)
plot(.c$`Predicted catch` * 1e3)
abline(h = na.omit(tac), col = "#00000001")
abline(h = median(na.omit(tac)), col = "red")
```


```{r}
# AvC <- .dshort$catch %>% gfplot::tidy_catch() %>% group_by(year) %>%
#   summarize(catch = sum(value)) %>% pull(catch) %>% mean()
# AvC <- AvC / 1000

.c <- readr::read_csv(here::here("report/data/shortraker-corrected-catch.csv"))
.c <- .c$`Predicted catch` * 1e3
plot(.c)
AvC <- mean(AvC)

short_dat <- new('Data')                            #  Create a blank DLM object
short_dat@Name <- 'Shortraker Rockfish'             #  Name it
short_dat@Units <- "T"                              #  units of catch
short_dat@AvC <- AvC                                #  Average catches for time t (DCAC)
short_dat@Cat <- matrix(.c, nrow = 1)
# short_dat@t <- 42
short_dat@Year <- 1977:2018
short_dat@t <- 2018 - 1977 + 1
short_dat@LHYear <- 2018

# FIXME: fake for now: {
short_dat@Ind <- matrix(rlnorm(short_dat@t, sdlog = 0.2), nrow = 1)
plot(t(short_dat@Ind))
short_dat@CV_Ind <- 0.5
# }

short_dat@sigmaR <- 0.78 # from meta-analysis

short_dat@Mort <- 0.03                              #  Natural mortality rate
short_dat@CV_Mort <- 0.2

# short_dat@BMSY_B0 <- 0.40                           #  BMSY relative to unfished
# short_dat@CV_BMSY_B0 <- 0.045

# short_dat@Dt <- 0.6                                 #  Depletion over time t (DCAC)
# short_dat@CV_Dt <- 0.4

# short_dat@FMSY_M <- 0.75                            #  Ratio of FMSY/M
# short_dat@CV_FMSY_M <- 0.2

mvb <- gfplot::fit_vb(.dshort$survey_samples, sex = "all")
mvb_summary <- summary(TMB::sdreport(mvb$model))
se <- mvb_summary[,"Std. Error"]
cv <- se / abs(mvb_summary[,"Estimate"])
gfplot::plot_vb(object_all = mvb, col = c("All" = "black"))
short_dat@vbLinf <- mvb$pars[["linf"]]
short_dat@vbK <- mvb$pars[["k"]]
short_dat@vbt0 <- mvb$pars[["t0"]]

short_dat@CV_vbK <- cv[["k"]]
short_dat@CV_vbLinf <- cv[["linf"]]
short_dat@CV_vbt0 <- cv[["t0"]]

m_mat <- gfplot::fit_mat_ogive(.dshort$survey_samples, type = "length")
mat_perc <- pbs2dlm:::extract_maturity_perc(coef(m_mat$model))
short_dat@L50 <- mat_perc$f.p0.5
short_dat@L95 <- mat_perc$f.p0.95

mlw <- gfplot::fit_length_weight(.dshort$survey_samples, sex = "all")
gfplot::plot_length_weight(object_all = mlw, col = c("All" = "black"))
.summary <- summary(TMB::sdreport(mlw$model))
se <- .summary[,"Std. Error"]
sd2cv <- function(.sd) sqrt(exp(.sd^2) - 1)
short_dat@wlb <- mlw$pars[["b"]]
short_dat@wla <- exp(mlw$pars[["log_a"]])
short_dat@CV_wla <- sd2cv(se[["log_a"]]) # log scale
short_dat@CV_wlb <- se[["b"]] / mlw$pars[["b"]]

short_dat@MaxAge <- om@maxage

# GB_CC needs Cref and optionally define CV_Cref

Fease(short_dat)

library(MSEtool)
# xx <- runMP(short_dat, MPs = "DD_TMB", reps = 1)

m <- DD_SS(Data = short_dat, fix_tau = TRUE, start = list(tau = 0.3))
m <- SP_SS(Data = short_dat, fix_tau = TRUE, start = list(tau = 0.3))
# m <- SP_SS(Data = short_dat, fix_tau = TRUE, start = list(tau = 0.3))

m <- SP_75MSY(Data = short_dat, fix_tau = TRUE, start = list(tau = 0.3))

m

mp <- c(
  # "DCAC",
  # "DCAC_40",
  # "DBSRA4010",
  # "DBSRA",
  # "DBSRA_40",
  # "DCAC4010",
  "AvC",
  "CC1",
  # "CC2",
  # "CC3",
  # "CC4",
  # "CC5",
  "SPSRA",
  "SPMSY",
  "NFref",
  "FMSYref",
  "FMSYref50",
  # "DD",
  # "DD4010",
  "GB_CC"
  # "DDSS_75MSY",
  # "SCA_75MSY",
  # "SP_75MSY"
  )
o <- runMSE(om, MPs = mp, parallel = .parallel)

# xx <- runMP(short_dat, MPs = "DCAC4010", reps = 10000)
tac <- as.vector(xx@TAC)
hist(tac, breaks = 40)
plot(.c)
abline(h = na.omit(tac), col = "#00000001")
abline(h = median(na.omit(tac)), col = "red")
```

<!-- Try to fit the delay difference model to our simulation data: -->

<!-- ```{r} -->
<!-- library(MSEtool) -->
<!-- om <- new('OM', stock, fleet, obs, imp) -->
<!-- .parallel <- !identical(.Platform$OS.type, "windows") -->
<!-- if (.parallel) DLMtool::setup(cpus = parallel::detectCores()) -->
<!-- om@nsim <- 100 -->
<!-- DD_MSY <- MSEtool::make_MP(DD_TMB, HCR_MSY, diagnostic = "full") -->

<!-- x <- MSEtool::prelim_AM(x = om, Assess = DD_TMB) -->

<!-- myMSE <- runMSE(OM = om, MPs = "DD_MSY", PPD = TRUE) -->
<!-- diagnostic_AM(myMSE) -->
<!-- retrospective_AM(myMSE, sim = 1, MP = "DD_MSY") -->

<!-- cpue <- readr::read_csv(here::here("report/data/shortraker-cpue.csv")) -->

<!-- short_dat@Ind <- matrix(c(13, cpue$est) / mean(c(13, cpue$est)), nrow = 1) -->
<!-- short_dat@CV_Ind <- mean(cpue$se_link) -->

<!-- system.time({ -->
<!--   m <- DD_SS(Data = short_dat, fix_tau = TRUE, start = list(tau = 0.7)) -->
<!-- }) -->
<!-- plot(m) -->
<!-- m -->
<!-- m1 <- DD_TMB(Data = short_dat) -->
<!-- plot(m1) -->
<!-- ``` -->
